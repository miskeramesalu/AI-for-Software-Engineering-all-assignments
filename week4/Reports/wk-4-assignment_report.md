# Week 4 — AI in Software Engineering (Report Summary)

## Task 1 — 200-word analysis (AI code completion)
AI-assisted code completion tools such as GitHub Copilot and Tabnine accelerate routine coding tasks by suggesting idiomatic code patterns and boilerplate. For the task of sorting a list of dictionaries by a key, an AI suggestion typically offers a concise `sorted(items, key=lambda d: d.get(key, None))` solution which is readable and efficient for homogeneous datasets. However, production-grade code must consider edge cases — missing keys, `None` values, and heterogeneous comparable types — where such concise suggestions can fail at runtime or produce nondeterministic ordering. A manual implementation that normalizes key access and places missing values consistently (for example, treating `None` as greater than real values to push them to the list end) provides more predictable behavior and easier debugging. Both approaches use Python’s Timsort with O(n log n) complexity; the primary trade-offs are memory (sorted() builds a new list) and robustness. The recommended workflow is to accept AI suggestions for initial drafts, then harden them with explicit validation or fallback logic for production use. This hybrid approach yields developer productivity gains while maintaining reliability and deterministic behavior under diverse real-world inputs.

## Task 2 — 150-word analysis (AI-enhanced automated testing)
AI augments automated testing by making locators and test-case generation more resilient and comprehensive. Tools that analyze historical DOM changes and failure traces can suggest robust selectors and prioritize test scenarios that historically catch regressions. AI can also synthesize variant inputs, generating boundary and negative cases that expand coverage beyond naive test suites. For flaky tests, AI-driven clustering of failure telemetry helps triage and quarantine tests, allowing engineering teams to focus on stable regressions. In practice, AI works best as an assistant: it proposes locators, data variants, and scenario permutations while human testers validate and curate the high-value cases. When paired with traditional Selenium + pytest frameworks, AI improves test durability and reduces maintenance overhead, especially on rapidly changing UI surfaces.

## Ethical reflection
Potential biases in predictive pipelines include sampling bias, label bias, measurement bias, and concept drift. Sampling bias occurs if training data underrepresents particular teams or modules; label bias emerges when human-assigned priorities reflect managerial preferences rather than objective severity. Measurement bias appears when feature collection differs across teams, and concept drift happens as product behavior evolves. Mitigation steps include bias detection (using metrics like disparate impact), preprocessing reweighing, in-processing fairness-aware algorithms, post-processing calibration, continuous monitoring, and human-in-the-loop review for high-impact predictions. Tools like IBM AI Fairness 360 provide a library of metrics and mitigation algorithms to operationalize fairness checks. Documenting data provenance, establishing labeling guidelines, and enabling appeals are essential for ethical deployment.

## Bonus — DocGen AI (one-paragraph)
DocGen AI automatically produces and maintains developer-facing documentation by ingesting code, tests, CI logs, and runtime telemetry. It leverages static analysis and LLM-based synthesis to draft README sections, API examples (validated in ephemeral sandboxes), changelogs, and migration notes. Generated docs are unit-verified and submitted as PRs with suggested reviewer comments, reducing documentation debt and improving onboarding velocity.
